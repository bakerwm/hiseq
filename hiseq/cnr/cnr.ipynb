{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "3f4bc290-8f3b-4e30-87e6-a2e2a4909aea",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-10-25T10:53:57.191086Z",
     "iopub.status.busy": "2021-10-25T10:53:57.190622Z",
     "iopub.status.idle": "2021-10-25T10:53:57.476838Z",
     "shell.execute_reply": "2021-10-25T10:53:57.476198Z",
     "shell.execute_reply.started": "2021-10-25T10:53:57.191041Z"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'input': 2, 'output': 2, 'name': 'M-polII', 'out_pct': 100.0, 'rm_pct': 0.0}"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## test utils\n",
    "%reload_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "import os\n",
    "from hiseq.utils.utils import *\n",
    "from hiseq.utils.file import list_dir\n",
    "\n",
    "f = '/data/yulab/wangming/work/yu_2021/projects/20211024_qd_pol2-yn/results/CnT/M-polII'\n",
    "a = read_hiseq(f)\n",
    "# a.hiseq_type\n",
    "# list_hiseq_dir(f, 'rx')\n",
    "def qc_trim_summary(x, hiseq_type='r1'):\n",
    "    \"\"\"\n",
    "    # format:\n",
    "    # name, input, output, out_pct, rm_pct\n",
    "    \"\"\"\n",
    "    a = read_hiseq(x, hiseq_type) # for general usage\n",
    "    if hiseq_type == 'auto':\n",
    "        hiseq_type = a.hiseq_type # auto\n",
    "    if not a.is_hiseq:\n",
    "        log.error('qc_trim_summary() skipped, not a hiseq dir: {}'.format(x))\n",
    "        return None\n",
    "    if a.is_hiseq_r1:\n",
    "        # option-1: stat.yaml\n",
    "        # option-2: stat.txt\n",
    "        stat_json = getattr(a, 'trim_json', None)\n",
    "        stat_txt = getattr(a, 'trim_stat', None)\n",
    "        # format:\n",
    "        # name, total, too_short, dup, too_short2, clean, percent\n",
    "        d = {\n",
    "            'name': a.smp_name,\n",
    "            'input': 1,\n",
    "            'output': 1,\n",
    "            'out_pct': 100.0,\n",
    "            'rm_pct': 0,\n",
    "        }\n",
    "        if file_exists(stat_json):\n",
    "            df = Config().load(stat_json) # laod data\n",
    "            d['input'] = int(df.get('total', 1))\n",
    "            d['output'] = int(df.get('clean', 1))\n",
    "            d['out_pct'] = float(df.get('percent', 100.0))\n",
    "            d['rm_pct'] = 100.0 - d['out_pct']\n",
    "        elif file_exists(stat_txt):\n",
    "            try:\n",
    "                s = None # init\n",
    "                with open(stat_txt) as r:\n",
    "                    for line in r:\n",
    "                        if line.startswith('#'):\n",
    "                            continue\n",
    "                        s = line.strip().split('\\t')\n",
    "                        break\n",
    "                if isinstance(s, list):\n",
    "                    d = {\n",
    "                        'name': s[0],\n",
    "                        'input': int(s[1]),\n",
    "                        'output': int(s[-2]),\n",
    "                        'out_pct': float(s[-1]),\n",
    "                        'rm_pct': 100.0 - float(s[-1]),\n",
    "                    }\n",
    "            except IOError as e:\n",
    "                log.error(e)\n",
    "        else:\n",
    "            log.error('trim.stat not exists: {}'.format(stat_txt))\n",
    "        # update pct\n",
    "        d['out_pct'] = float('{:.2f}'.format(d['out_pct']))\n",
    "        d['rm_pct'] = float('{:.2f}'.format(d['rm_pct']))\n",
    "        # save to new file\n",
    "        Config().dump(d, a.trim_summary_json)\n",
    "    elif a.is_hiseq_rn:\n",
    "        r1 = list_hiseq_file(x, 'trim_summary_json', 'r1')\n",
    "        d = {}\n",
    "        for i in r1:\n",
    "            di = Config().load(i)\n",
    "            d = {k:d.get(k, 0)+di.get(k, 0) for k,v in di.items() if type(v) == int} # merge values\n",
    "            d_str = {k:v for k,v in di.items() if type(v) == bool or type(v) == str}\n",
    "            d.update(d_str) # unique_only, index, name\n",
    "            d['name'] = list_hiseq_file(x, 'smp_name', 'auto') # update name\n",
    "            # update out_pct, rm_pct\n",
    "            d['out_pct'] = round(d.get('output', 0)/d.get('input', 1)*100, 2)\n",
    "            d['rm_pct'] = round(100-d.get('out_pct'), 2)\n",
    "        Config().dump(d, a.trim_summary_json)\n",
    "    else:\n",
    "        log.warning('qc_align_summary() skipped, no align_json')\n",
    "        return None\n",
    "    return d\n",
    "\n",
    "\n",
    "\n",
    "f = '/data/yulab/wangming/work/yu_2021/projects/20211024_qd_pol2-yn/results/CnT/M-polII'\n",
    "# qc_align_summary(f, 'rn')\n",
    "qc_trim_summary(f, 'rn')\n",
    "# list_hiseq_file(f, 'smp_name', 'rn')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "62c7592c-4cc6-4b7b-9324-0ad058abb3d5",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "## test utils\n",
    "%reload_ext autoreload\n",
    "%autoreload 2\n",
    "import os\n",
    "import sys\n",
    "from cnr_r1 import CnrR1\n",
    "from hiseq.utils.file import list_file\n",
    "from utils import *\n",
    "from hiseq.utils.utils import (\n",
    "    log, update_obj, Config, get_date, read_hiseq, list_hiseq_file, list_hiseq_dir,\n",
    "    run_shell_cmd, find_longest_common_str\n",
    ")\n",
    "\n",
    "hiseq_type = '_r1'\n",
    "\n",
    "# f = '/data/yulab/wangming/work/devel_pipeline/hiseq/cnr/results/fruitfly_v1/CUT_and_RUN_Piwi_RNAi_embryo_3_4h_H3K4me3_rep2'\n",
    "f = '/data/yulab/wangming/work/devel_pipeline/hiseq/cnr/results/fruitfly_v1/CUT_and_RUN_White_RNAi_embryo_3_4h_H3K4me3_rep2'\n",
    "\n",
    "x = '/data/yulab/wangming/work/devel_pipeline/hiseq/cnr/results/fruitfly_v1/CUT_and_RUN_Piwi_RNAi_embryo_3_4h_H3K4me3_rep1'\n",
    "x = '/data/yulab/wangming/work/devel_pipeline/hiseq/cnr/results/fruitfly_v1/CUT_and_RUN_White_RNAi_embryo_3_4h_H3K4me3_rep1'\n",
    "\n",
    "x = '/data/yulab/wangming/work/devel_pipeline/hiseq/cnr/results/fruitfly_v1/CUT_and_RUN_White_RNAi_embryo_3_4h_H3K4me3'\n",
    "\n",
    "# list_hiseq_file(x, 'align_json', 'r1')\n",
    "a = read_hiseq(x, 'rn')\n",
    "a.smp_name\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "detailed-military",
   "metadata": {},
   "outputs": [],
   "source": [
    "## test CnrR1\n",
    "\n",
    "%reload_ext autoreload\n",
    "%autoreload 2\n",
    "import os\n",
    "import sys\n",
    "from cnr_r1 import CnrR1\n",
    "from hiseq.utils.file import list_file\n",
    "\n",
    "\n",
    "data_dir = '/data/yulab/wangming/work/devel_pipeline/hiseq/cnr/data/fruitfly/'\n",
    "\n",
    "fq1 = list_file(data_dir, '*Piwi*K4*1.fq.gz')\n",
    "fq2 = list_file(data_dir, '*Piwi*K4*2.fq.gz')\n",
    "outdir = '/data/yulab/wangming/work/devel_pipeline/hiseq/cnr/output/fruitfly'\n",
    "\n",
    "args = {\n",
    "    'fq1': fq1[1],\n",
    "    'fq2': fq2[1],\n",
    "    'genome': 'dm6',\n",
    "    'outdir': outdir,\n",
    "    'threads': 12,\n",
    "    'parallel_jobs': 2\n",
    "}\n",
    "\n",
    "CnrR1(**args).run()\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "elect-shame",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "## test CnrRn\n",
    "\n",
    "%reload_ext autoreload\n",
    "%autoreload 2\n",
    "import os\n",
    "import sys\n",
    "from cnr_r1 import CnrR1\n",
    "from cnr_rn import CnrRn\n",
    "from hiseq.utils.file import list_file\n",
    "from hiseq.utils.utils import read_hiseq, Config, list_hiseq_file\n",
    "from utils import qc_frip\n",
    "\n",
    "# data_dir = '/data/yulab/wangming/work/devel_pipeline/hiseq/cnr/data/fruitfly/'\n",
    "\n",
    "\n",
    "# fq1 = list_file(data_dir, '*Piwi*IgG*1.fq.gz')\n",
    "# fq2 = list_file(data_dir, '*Piwi*IgG*2.fq.gz')\n",
    "\n",
    "# outdir = '/data/yulab/wangming/work/devel_pipeline/hiseq/cnr/output/fruitfly'\n",
    "\n",
    "# args = {\n",
    "#     'fq1': fq1,\n",
    "#     'fq2': fq2,\n",
    "#     'genome': 'dm6',\n",
    "#     'outdir': outdir,\n",
    "#     'threads': 12,\n",
    "#     'parallel_jobs': 4\n",
    "# }\n",
    "\n",
    "# CnrRn(**args).run()\n",
    "\n",
    "\n",
    "c = '/data/yulab/wangming/work/yu_2021/projects/20210421_lxh_CnR/results/CnR_v2/CnR_Nos_DaGal4XshPiwi_6-8h_IgG/config/config.yaml'\n",
    "args = Config().load(c)\n",
    "a = CnrRn(**args)\n",
    "# a.run_pipe_r1()\n",
    "a.run()\n",
    "\n",
    "# rep_dir = '/data/yulab/wangming/work/yu_2021/projects/20210421_lxh_CnR/results/CnR_v2/CnR_Nos_DaGal4XshPiwi_6-8h_IgG_rep1'\n",
    "# k = 'bam'\n",
    "# list_hiseq_file(rep_dir, k, 'r1')\n",
    "\n",
    "\n",
    "\n",
    "# x = '/data/yulab/wangming/work/devel_pipeline/hiseq/cnr/output/fruitfly/CUT_and_RUN_Piwi_RNAi_embryo_3_4h_H3K4me3/'\n",
    "# pd = read_hiseq(x)\n",
    "# qc_frip(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "common-purpose",
   "metadata": {},
   "outputs": [],
   "source": [
    "# test CnrRx # design\n",
    "\n",
    "%reload_ext autoreload\n",
    "%autoreload 2\n",
    "import os\n",
    "import sys\n",
    "from cnr_r1 import CnrR1\n",
    "from cnr_rn import CnrRn\n",
    "from cnr_rx import CnrRx\n",
    "from hiseq.utils.file import list_file\n",
    "from hiseq.utils.utils import read_hiseq, print_dict\n",
    "from utils import qc_frip\n",
    "data_dir = '/data/yulab/wangming/work/devel_pipeline/hiseq/cnr/data/fruitfly/'\n",
    "\n",
    "ip_fq1 = list_file(data_dir, '*White*K4*1.fq.gz')\n",
    "ip_fq2 = list_file(data_dir, '*White*K4*2.fq.gz')\n",
    "input_fq1 = list_file(data_dir, '*White*IgG*1.fq.gz')\n",
    "input_fq2 = list_file(data_dir, '*White*IgG*2.fq.gz')\n",
    "\n",
    "outdir = '/data/yulab/wangming/work/devel_pipeline/hiseq/cnr/output/fruitfly'\n",
    "\n",
    "args = {\n",
    "    'ip_fq1': ip_fq1,\n",
    "    'ip_fq2': ip_fq2,\n",
    "    'input_fq1': input_fq1,\n",
    "    'input_fq2': input_fq2,\n",
    "    'genome': 'dm6',\n",
    "    'outdir': outdir,\n",
    "    'threads': 12,\n",
    "    'parallel_jobs': 4,\n",
    "    'gene_bed': '/home/wangming/data/genome/dm6/annotation_and_repeats/dm6.ensembl.bed',\n",
    "}\n",
    "\n",
    "CnrRx(**args).run()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "searching-fundamental",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "\n",
    "def parse_report(in_report, out_stat, topN=10, tax_level='G'):\n",
    "        \"\"\"\n",
    "        Parameters\n",
    "        ----------\n",
    "        in_report: str\n",
    "            The --report output of kraken2\n",
    "            \n",
    "        out_stat: str\n",
    "            The file saving the simplified report, by specific tax level\n",
    "            \n",
    "        topN: int\n",
    "            The top N taxon, default: 100\n",
    "            \n",
    "        tax_level: str\n",
    "            The specific tax level to show, default: ['G'],\n",
    "            options: [D, K, P, C, O, F, G, S]\n",
    "        \n",
    "        parse Kraken2 report (--report)\n",
    "        Inspect the output of kraken2 report file\n",
    "        pandas table\n",
    "        \n",
    "        col-1: Percentage of fragments covered by the clade rooted at this taxon\n",
    "        col-2: Number of fragments covered by the clade rooted at this taxon\n",
    "        col-3: Number of fragments assigned directly to this taxon\n",
    "        col-4: A rank code, indicating (U)nclassified, (R)oot, (D)omain, \n",
    "               (K)ingdom, (P)hylum, (C)lass, (O)rder, (F)amily, (G)enus,\n",
    "               or (S)pecies. Taxa that are not at any of these 10 ranks have \n",
    "               a rank code that is formed by using the rank code of the closest\n",
    "               ancestor rank with a number indicating the distance from that rank.\n",
    "               E.g., \"G2\" is a rank code indicating a taxon is between genus and \n",
    "               species and the grandparent taxon is at the genus rank.\n",
    "        col-5: NCBI taxonomic ID number\n",
    "        col-6: Indented scientific name\n",
    "        \n",
    "        # choose the top species, by col-3, read directly in taxon\n",
    "        \"\"\"\n",
    "        s = ['pct', 'reads_in_clade', 'reads_in_tax', 'code', 'taxid', 'name']\n",
    "        try:\n",
    "            df1 = pd.read_csv(in_report, '\\t', names=s)\n",
    "        except IOError as e:\n",
    "            log.error(e)\n",
    "            return None\n",
    "        # choose Geneus (G); root, unclassified\n",
    "        df_un = df1.loc[df1['code'] == 'U'] # unclassified\n",
    "        df_root = df1.loc[df1['code'] == 'R'] # root\n",
    "        df_tax = df1.loc[df1['code'].isin([tax_level]), ] # eg: G\n",
    "        # choose top ranked taxon\n",
    "        df_tax = df_tax.sort_values(['reads_in_tax'], ascending=False)\n",
    "        # sub-sample\n",
    "        df2 = df_tax.loc[0:topN,]\n",
    "#         # combine\n",
    "#         df = pd.concate([df_un, df2])\n",
    "        ## remove white spaces\n",
    "#         df['name'] = df['name'].str.strip()\n",
    "#         # add sample name\n",
    "#         df['sample'] = file_prefix(x) # prefix\n",
    "#         # get total\n",
    "#         n_hit = df_root.loc[:, 'reads_in_clade']\n",
    "#         n_unhit = df_un.loc[:, 'reads_in_clade']\n",
    "#         # adt pct\n",
    "#         df['reads_hit'] = int(n_hit) # root\n",
    "#         df['reads_total'] = int(n_hit) + int(n_unhit) # root + unclassified\n",
    "#         df['hit_pct'] = df['reads_in_tax'] / int(n_hit) * 100\n",
    "#          # sub-sample\n",
    "#         df3 = df.loc[:,['sample', 'name', 'reads_in_tax', 'hit_pct', 'reads_hit', 'reads_total']]        \n",
    "#         # custome options\n",
    "#         with pd.option_context('display.expand_frame_repr', False, 'display.max_colwidth', 20):\n",
    "#             print(df3)\n",
    "#         # save to file\n",
    "#         df3.to_csv(out_stat, sep='\\t', index=False)\n",
    "#         return df3\n",
    "\n",
    "in_report = '/data/yulab/wangming/work/devel_pipeline/hiseq/qc/aaaa.kraken2.report'\n",
    "out_stat = '/data/yulab/wangming/work/devel_pipeline/hiseq/qc/aaaa.kraken2.stat'\n",
    "topN = 10\n",
    "# parse_report(in_report, out_stat)\n",
    "tax_level = 'G'\n",
    "s = ['pct', 'reads_in_clade', 'reads_in_tax', 'code', 'taxid', 'name']\n",
    "try:\n",
    "    df1 = pd.read_csv(in_report, '\\t', names=s)\n",
    "except IOError as e:\n",
    "    log.error(e)\n",
    "# choose Geneus (G); root, unclassified\n",
    "df_un = df1.loc[df1['code'] == 'U'] # unclassified\n",
    "df_root = df1.loc[df1['code'] == 'R'] # root\n",
    "df_tax = df1.loc[df1['code'].isin([tax_level]), ] # eg: G\n",
    "# choose top ranked taxon\n",
    "df_tax = df_tax.sort_values(['reads_in_tax'], ascending=False)\n",
    "# sub-sample\n",
    "df2 = df_tax.iloc[0:topN,]\n",
    "df2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "attached-adaptation",
   "metadata": {},
   "outputs": [],
   "source": [
    " all([False])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "filled-connectivity",
   "metadata": {},
   "outputs": [],
   "source": [
    "# test CnrRd # design\n",
    "%reload_ext autoreload\n",
    "%autoreload 2\n",
    "from cnr_rd import CnrRd\n",
    "\n",
    "data_dir = '/data/yulab/wangming/work/devel_pipeline/hiseq/cnr/data/fruitfly/'\n",
    "\n",
    "ip_fq1 = list_file(data_dir, '*Piwi*K4*1.fq.gz')\n",
    "ip_fq2 = list_file(data_dir, '*Piwi*K4*2.fq.gz')\n",
    "\n",
    "input_fq1 = list_file(data_dir, '*Piwi*IgG*1.fq.gz')\n",
    "input_fq2 = list_file(data_dir, '*Piwi*IgG*2.fq.gz')\n",
    "outdir = '/data/yulab/wangming/work/devel_pipeline/hiseq/cnr/output/fruitfly'\n",
    "\n",
    "args = {\n",
    "    'design': 'aaa.toml',\n",
    "    'fq_dir': data_dir,\n",
    "    'ip_fq1': ip_fq1,\n",
    "    'ip_fq2': ip_fq2,\n",
    "    'input_fq1': input_fq1,\n",
    "    'input_fq2': input_fq2\n",
    "}\n",
    "\n",
    "\n",
    "args = {\n",
    "    'design': 'aaa.toml',\n",
    "    'fq_dir': data_dir,\n",
    "    'ip': ['Piwi_RNAi_embryo_3_4h_H3K4me3', 'White_RNAi_embryo_3_4h_H3K4me3'],\n",
    "    'input': ['Piwi_RNAi_embryo_3_4h_IgG'],\n",
    "}\n",
    "\n",
    "a = CnrRd(**args)\n",
    "\n",
    "#a.check_fx_args()\n",
    "df = a.run()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "unauthorized-nightmare",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "from difflib import SequenceMatcher\n",
    "\n",
    "string1 = \"apple pie available\"\n",
    "string2 = \"come have some apple pies\"\n",
    "\n",
    "# match = SequenceMatcher(None, string1, string2).find_longest_match(0, len(string1), 0, len(string2))\n",
    "\n",
    "# print(match)  # -> Match(a=0, b=15, size=9)\n",
    "# print(string1[match.a: match.a + match.size])  # -> apple pie\n",
    "# print(string2[match.b: match.b + match.size])  # -> apple pie\n",
    "\n",
    "# string1[match.a:match.a+match.size]\n",
    "\n",
    "# dir(match)\n",
    "\n",
    "\n",
    "## Temp\n",
    "def find_longest_common_str(s1, s2):\n",
    "    if isinstance(s1, str) and isinstance(s2, str):\n",
    "        m = SequenceMatcher(None, s1, s2) # match\n",
    "        l = m.find_longest_match(0, len(s1), 0, len(s2))\n",
    "        out = s1[l.a: l.a + l.size]\n",
    "    else:\n",
    "        log.error('only support str, got s1={} s2={}'.type(\n",
    "            type(s1).__name__, type(s2).__name__))\n",
    "        out = None\n",
    "    return out\n",
    "\n",
    "find_longest_common_str('abc', 'efgab')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "0df14f83-b1cc-49fa-9edb-39c67ef25527",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-10-22T08:50:41.241466Z",
     "iopub.status.busy": "2021-10-22T08:50:41.240937Z",
     "iopub.status.idle": "2021-10-22T08:50:44.880623Z",
     "shell.execute_reply": "2021-10-22T08:50:44.879977Z",
     "shell.execute_reply.started": "2021-10-22T08:50:41.241414Z"
    },
    "scrolled": true,
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2021-10-22 16:50:42 WARNING] unknown hiseq dir: /data/yulab/wangming/work/yu_2021/projects/20211021_qd_CnT_mouse_yy80/results/CnT\n",
      "[2021-10-22 16:50:42 WARNING] copy_file() failed, src not vaild: /data/yulab/wangming/work/yu_2021/projects/20211021_qd_CnT_mouse_yy80/results/CnT/CnT_mHaploid_IgG/qc/00.trim_summary.json\n",
      "[2021-10-22 16:50:42 WARNING] copy_file() failed, src not vaild: /data/yulab/wangming/work/yu_2021/projects/20211021_qd_CnT_mouse_yy80/results/CnT/CnT_mHaploid_IgG/qc/01.alignment_summary.json\n",
      "[2021-10-22 16:50:42 WARNING] copy_file() failed, src not vaild: /data/yulab/wangming/work/yu_2021/projects/20211021_qd_CnT_mouse_yy80/results/CnT/CnT_mHaploid_IgG/qc/01.pcr_dup_summary.json\n",
      "[2021-10-22 16:50:42 WARNING] copy_file() failed, src not vaild: /data/yulab/wangming/work/yu_2021/projects/20211021_qd_CnT_mouse_yy80/results/CnT/CnT_mHaploid_IgG/qc/02.length_distribution.csv\n",
      "[2021-10-22 16:50:42 WARNING] copy_file() failed, src not vaild: /data/yulab/wangming/work/yu_2021/projects/20211021_qd_CnT_mouse_yy80/results/CnT/CnT_mHaploid_IgG/qc/04.tss_enrich.png\n",
      "[2021-10-22 16:50:42 WARNING] copy_file() failed, src not vaild: /data/yulab/wangming/work/yu_2021/projects/20211021_qd_CnT_mouse_yy80/results/CnT/CnT_mHaploid_IgG/qc/05.genebody_enrich.png\n",
      "[2021-10-22 16:50:43 WARNING] copy_file() failed, src not vaild: /data/yulab/wangming/work/yu_2021/projects/20211021_qd_CnT_mouse_yy80/results/CnT/CnT_mHaploid_IgG_rep1/qc/01.pcr_dup_summary.json\n",
      "[2021-10-22 16:50:43 WARNING] copy_file() failed, src not vaild: /data/yulab/wangming/work/yu_2021/projects/20211021_qd_CnT_mouse_yy80/results/CnT/CnT_mHaploid_IgG_rep2/qc/01.pcr_dup_summary.json\n",
      "[2021-10-22 16:50:43 WARNING] copy_file() failed, src not vaild: /data/yulab/wangming/work/yu_2021/projects/20211021_qd_CnT_mouse_yy80/results/CnT/CnT_mHaploid_POL2/qc/00.trim_summary.json\n",
      "[2021-10-22 16:50:43 WARNING] copy_file() failed, src not vaild: /data/yulab/wangming/work/yu_2021/projects/20211021_qd_CnT_mouse_yy80/results/CnT/CnT_mHaploid_POL2/qc/01.alignment_summary.json\n",
      "[2021-10-22 16:50:43 WARNING] copy_file() failed, src not vaild: /data/yulab/wangming/work/yu_2021/projects/20211021_qd_CnT_mouse_yy80/results/CnT/CnT_mHaploid_POL2/qc/01.pcr_dup_summary.json\n",
      "[2021-10-22 16:50:43 WARNING] copy_file() failed, src not vaild: /data/yulab/wangming/work/yu_2021/projects/20211021_qd_CnT_mouse_yy80/results/CnT/CnT_mHaploid_POL2/qc/02.length_distribution.csv\n",
      "[2021-10-22 16:50:43 WARNING] copy_file() failed, src not vaild: /data/yulab/wangming/work/yu_2021/projects/20211021_qd_CnT_mouse_yy80/results/CnT/CnT_mHaploid_POL2/qc/04.tss_enrich.png\n",
      "[2021-10-22 16:50:43 WARNING] copy_file() failed, src not vaild: /data/yulab/wangming/work/yu_2021/projects/20211021_qd_CnT_mouse_yy80/results/CnT/CnT_mHaploid_POL2/qc/05.genebody_enrich.png\n",
      "[2021-10-22 16:50:44 WARNING] copy_file() failed, src not vaild: /data/yulab/wangming/work/yu_2021/projects/20211021_qd_CnT_mouse_yy80/results/CnT/CnT_mHaploid_POL2.vs.CnT_mHaploid_IgG/qc/04.tss_enrich.png\n",
      "[2021-10-22 16:50:44 WARNING] copy_file() failed, src not vaild: /data/yulab/wangming/work/yu_2021/projects/20211021_qd_CnT_mouse_yy80/results/CnT/CnT_mHaploid_POL2.vs.CnT_mHaploid_IgG/qc/05.genebody_enrich.png\n",
      "[2021-10-22 16:50:44 WARNING] copy_file() failed, src not vaild: /data/yulab/wangming/work/yu_2021/projects/20211021_qd_CnT_mouse_yy80/results/CnT/CnT_mHaploid_POL2.vs.CnT_mHaploid_IgG/qc/08.peak_overlap.png\n",
      "[2021-10-22 16:50:44 WARNING] copy_file() failed, src not vaild: /data/yulab/wangming/work/yu_2021/projects/20211021_qd_CnT_mouse_yy80/results/CnT/CnT_mHaploid_POL2_rep1/qc/01.pcr_dup_summary.json\n",
      "[2021-10-22 16:50:44 WARNING] copy_file() failed, src not vaild: /data/yulab/wangming/work/yu_2021/projects/20211021_qd_CnT_mouse_yy80/results/CnT/CnT_mHaploid_POL2_rep2/qc/01.pcr_dup_summary.json\n"
     ]
    }
   ],
   "source": [
    "%reload_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "import os\n",
    "from hiseq.utils.utils import list_hiseq_file\n",
    "from hiseq.utils.file import copy_file\n",
    "from cnr_merge import *\n",
    "\n",
    "\n",
    "args = {\n",
    "    'indir': '/data/yulab/wangming/work/yu_2021/projects/20211021_qd_CnT_mouse_yy80/results/CnT',\n",
    "    'outdir': '/data/yulab/wangming/work/yu_2021/projects/20211021_qd_CnT_mouse_yy80/merge',\n",
    "}\n",
    "\n",
    "a = CnrMerge(**args)\n",
    "a.run()\n",
    "# a.project_dir\n",
    "# copy_hiseq_qc(a.project_dir)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "a5f2c9db-3e1f-456e-ae04-1e308e6cbfad",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-10-22T12:33:12.064259Z",
     "iopub.status.busy": "2021-10-22T12:33:12.063724Z",
     "iopub.status.idle": "2021-10-22T12:33:12.098049Z",
     "shell.execute_reply": "2021-10-22T12:33:12.097388Z",
     "shell.execute_reply.started": "2021-10-22T12:33:12.064207Z"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'2fc06e87f49f8993d32004be09beb02799f5bfa5ccc0c7eb71a99d71fe4675a6'"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import hashlib\n",
    "import uuid\n",
    "## for hash string  \n",
    "\n",
    "## for hash string; version with random number\n",
    "def hash_string(s):\n",
    "    return hashlib.sha256(s.encode()).hexdigest()\n",
    "\n",
    "\n",
    "def check_hash_string(hash_s, s):\n",
    "    \"\"\"\n",
    "    Parameters:\n",
    "    hash_s  : str\n",
    "        The SHA-256 value for the input string \n",
    "        also, could be the first few characters of the SHA-256 value\n",
    "        \n",
    "    s  : str\n",
    "        The string for checking\n",
    "    \"\"\"\n",
    "    # hash_s, could be the first few characters, (8?)\n",
    "    hs = hash_string(s)\n",
    "    return hs.startswith(hash_s) or hs == s\n",
    "\n",
    "# a = hash_string('hello') \n",
    "# # check_hashed_string(a, 'hello')\n",
    "# b = '2cf24dba'\n",
    "\n",
    "# check_hash_string(b, 'hello')\n",
    "# len(a)\n",
    "\n",
    "s = '/data/yulab/wangming/work/yu_2021/projects/20211021_qd_CnT_mouse_yy80/results/CnT'\n",
    "\n",
    "hash_string(s)\n",
    "\n",
    "# s.encode()\n",
    "\n",
    "# hashlib.sha256(s).hexdigest()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
