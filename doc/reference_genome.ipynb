{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "dynamic-spencer",
   "metadata": {},
   "source": [
    "# Reference genome\n",
    "\n",
    "\n",
    "There are multiple source of reference genome data: [Ensembl](), [UCSC](), [NCBI](), [GENCODE](), ... \n",
    "\n",
    "\n",
    "## 1. Archived\n",
    "\n",
    "Also, here are the collection of reference genome and annotations: \n",
    "\n",
    "  - [iGenomes](https://support.illumina.com/sequencing/sequencing_software/igenome.html) - Ready-To-Use Reference Sequences and Annotations from Illumina. The files were downloaded from [Ensembl](), [NCBI]() or [UCSC](). \n",
    "  \n",
    "  - [refgenie](http://refgenomes.databio.org/) - A website collect data for common species, and provide RESTfull API to access the data. see [API doc](http://refgenomes.databio.org/docs) for the RESTful API. And also support CLI tool to download data: `refgenie pull ...`, see the [refgenie](http://refgenie.databio.org/en/latest/) Documentation.\n",
    "\n",
    "  - [GenomeResouces](http://zhanglab.net/resources/genome/Home.html) - Collection of common Genome Annotations and Resources, by Zhang Qiangfeng lab (Tsinghua University)     \n",
    "\n",
    "## 2. Manual Download\n",
    "\n",
    "Download GTF annotation data from Ensembl.\n",
    "\n",
    "Use [CrossMap](http://crossmap.sourceforge.net/) (on github: https://github.com/liguowang/CrossMap) to convert genome coordinates between different assemblies (like liftOver).\n",
    "\n",
    "See [ChromosomeMappings](https://github.com/dpryan79/ChromosomeMappings) - by Devon Ryan, to convert chromosome names between UCSC <-> Ensembl <-> Gencode for a variety of genomes.\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "http://igenomes.illumina.com.s3-website-us-east-1.amazonaws.com/Drosophila_melanogaster/Ensembl/BDGP6/Drosophila_melanogaster_Ensembl_BDGP6.tar.gz\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "## 3. Using Refgenie from Python\n",
    "\n",
    "### 3.1 Download pre-build assemblies   \n",
    "\n",
    "```\n",
    "$ refgenie pull -g dm6 fasta bowtie2_index ensembl_gtf   \n",
    "$ refgenie pull -g hg38 fasta bowtie2_index ensembl_gtf   \n",
    "```\n",
    "\n",
    "### 3.2 Add custom assets\n",
    "\n",
    "Prepare custom annotation data for genome, for example, add `bed` for dm6\n",
    "\n",
    "```\n",
    "# go to genome dir\n",
    "```\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "For example, add `dm6` assembly\n",
    "\n",
    "  - Create a empty dir within `$genome_data` directory: `dm6/fasta`   \n",
    "  - Build the fasta and annotation assets, using the following commands\n",
    "  \n",
    "  \n",
    "```\n",
    "# create dm6\n",
    "$ cd /data/biodata/refgenie/\n",
    "$ mkdir -p dm6/fasta\n",
    "# add genome\n",
    "$ refgenie add dm6/fasta -p dm6/fasta\n",
    "# Caution!!!, \n",
    "# Change the asset_path: [dm6/fasta] to [fasta] in genome_config.yaml file\n",
    "# build\n",
    "$ wget ftp://ftp.ensembl.org/pub/release-102/fasta/drosophila_melanogaster/dna/Drosophila_melanogaster.BDGP6.28.dna.toplevel.fa.gz \n",
    "$ refgenie build dm6/fasata --files fasta=Drosophila_melanogaster.BDGP6.28.dna.toplevel.fa.gz \n",
    "# build more assets\n",
    "$ refgenie build -g dm6 bowtie_index bowtie2_index bwa_index kallisto_index\n",
    "# STAR for small genome, change genomeSAindexNbases to 6 or 5. default: 14 (10-15)\n",
    "$ refgenie build -g dm6 star_index --params genomeSAindexNbases=6\n",
    "```\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "### 3.3 Build assets\n",
    "\n",
    "**All files must be gzipped as input** - in current version: refgenie 0.9.3\n",
    "\n",
    "\n",
    "#### 3.3.1 Reference\n",
    "\n",
    "+ fasta\n",
    "\n",
    "```\n",
    "# require: fasta, samtools\n",
    "$ refgenie build dm6/fasta --files=dm6.fa.gz\n",
    "```\n",
    "\n",
    "\n",
    "\n",
    "#### Annotations\n",
    "\n",
    "\n",
    "+ ensembl_gtf \n",
    "\n",
    "```\n",
    "# swith to refgenic HOME\n",
    "$ cd /data/biodata/refgenie\n",
    "\n",
    "# create dir \n",
    "$ mkdir -p dm6/ensembl_gtf/default/\n",
    "\n",
    "# copy/download ensembl data\n",
    "$ cp Drosophila_melanogaster.BDGP6.28.102.gtf.gz dm6/ensembl_gtf/default/dm6_ensembl.gtf.gz\n",
    "\n",
    "# build\n",
    "$ refgenie build dm6/ensembl_gtf --files ensembl_gtf=dm6/ensembl_gtf/default/dm6_ensembl.gtf.gz\n",
    "\n",
    "```\n",
    "\n",
    "#### Indexes for aligner: `bowtie`, `bowtie2`, `hisat2`, `bwa`, `STAR`, `kallisto`, `salmon`\n",
    "\n",
    "\n",
    "+ bowtie_index   \n",
    "\n",
    "```\n",
    "# require: fasta, bowtie2\n",
    "$ refgenie build dm6/bowtie_index\n",
    "```\n",
    "\n",
    "+ bowtie2_index   \n",
    "\n",
    "```\n",
    "# require: fasta, bowtie2\n",
    "$ refgenie build dm6/bowtie2_index\n",
    "```\n",
    "\n",
    "+ hisat2_index\n",
    "\n",
    "```\n",
    "# require: fasta, hisat2\n",
    "$ refgenie build dm6/hisat2_index\n",
    "```\n",
    "\n",
    "+ bwa_index\n",
    "\n",
    "```\n",
    "# require: fasta, bwa\n",
    "$ refgenie build dm6/bwa_index\n",
    "```\n",
    "\n",
    "+ kallisto_index \n",
    "\n",
    "```\n",
    "# require: fasta, kallisto\n",
    "$ refgenie build dm6/kallisto_index\n",
    "```\n",
    "\n",
    "+ salmon_index\n",
    "\n",
    "```\n",
    "# require: fasta, salmon\n",
    "$ refgenie build dm6/salmon_index\n",
    "```\n",
    "\n",
    "+ star_index\n",
    "\n",
    "```\n",
    "# require: fasta, STAR\n",
    "$ refgenie build dm6/star_index\n",
    "```\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "## Extract TSS, gene_body\n",
    "\n",
    "Ensembl annotated TSS and real TSS?    \n",
    "see: https://www.ncbi.nlm.nih.gov/pmc/articles/PMC3531148/    \n",
    "DOI: 10.1093/nar/gks1233    \n",
    "title: EPD and EPDnew, high-quality promoter resources in the next-generation sequencing era    \n",
    "> substantial fraction of the gene starts in ENSEMBL are in fact located 10â€“20 bp downstream of the true TSS.\n",
    "\n",
    "from `refgenie build` function, The TSS were moved 20bp downstream.(file: `refgenie/asset_build_packages.py` line-457)\n",
    "\n",
    "Why?\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "understanding-insert",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "healthy-bermuda",
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "import sys\n",
    "\n",
    "server = \"https://rest.ensembl.org\"\n",
    "ext = \"/archive/id/ENSG00000157764?\"\n",
    " \n",
    "r = requests.get(server+ext, headers={ \"Content-Type\" : \"application/json\"})\n",
    " \n",
    "if not r.ok:\n",
    "  r.raise_for_status()\n",
    "  sys.exit()\n",
    " \n",
    "decoded = r.json()\n",
    "print(repr(decoded))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "animated-pressure",
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "import sys\n",
    "\n",
    "server = \"https://rest.ensembl.org\"\n",
    "ext = \"/info/rest?\"\n",
    " \n",
    "r = requests.get(server+ext, headers={ \"Content-Type\" : \"application/json\"})\n",
    " \n",
    "if not r.ok:\n",
    "  r.raise_for_status()\n",
    "  sys.exit()\n",
    " \n",
    "decoded = r.json()\n",
    "print(repr(decoded))\n",
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "substantial-protocol",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-02-04T01:58:24.566116Z",
     "iopub.status.busy": "2021-02-04T01:58:24.565574Z",
     "iopub.status.idle": "2021-02-04T01:58:24.621410Z",
     "shell.execute_reply": "2021-02-04T01:58:24.620537Z",
     "shell.execute_reply.started": "2021-02-04T01:58:24.566064Z"
    }
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import yaml\n",
    "import toml\n",
    "import pickle\n",
    "import json\n",
    "\n",
    "class Config(object):\n",
    "    \"\"\"Working with config, in dict/yaml/toml/pickle formats\n",
    "    load/dump\n",
    "    \n",
    "    Example:\n",
    "    1. write to file\n",
    "    >>> Config(d).dump('out.json')\n",
    "    >>> Config(d).dump('out.toml')\n",
    "    >>> Config(d).dump('out.pickle')\n",
    "    \n",
    "    2. load from file\n",
    "    >>> d = Config().load('in.yaml')\n",
    "\n",
    "    read/write data\n",
    "    \"\"\"\n",
    "    def __init__(self, x=None, **kwargs):\n",
    "        self = update_obj(self, kwargs, force=True)\n",
    "        self.x = x\n",
    "\n",
    "\n",
    "    def load(self, x=None):\n",
    "        \"\"\"Read data from x, auto-recognize the file-type\n",
    "        toml\n",
    "        json\n",
    "        pickle\n",
    "        txt\n",
    "        ...\n",
    "        \"\"\"\n",
    "        if x == None:\n",
    "            x = self.x # dict or str\n",
    "\n",
    "        if x is None:\n",
    "            x_dict = None # {} ?\n",
    "        elif isinstance(x, dict):\n",
    "            x_dict = collections.OrderedDict(sorted(x.items()))\n",
    "        elif isinstance(x, str):\n",
    "            reader = self.get_reader(x)\n",
    "            if reader is None:\n",
    "                x_dict = None\n",
    "                log.error('unknown x, {}'.format(x))\n",
    "            else:\n",
    "                x_dict = reader(x)\n",
    "        else:\n",
    "            x_dict = None\n",
    "            log.warning('dump(x=) dict,str expect, got {}'.format(\n",
    "                type(x).__name__))\n",
    "\n",
    "        return x_dict\n",
    "\n",
    "\n",
    "    def dump(self, d=None, x=None):\n",
    "        \"\"\"Write data to file x, auto-recognize the file-type\n",
    "        d str or dict, data\n",
    "        x str file to save data(dict)\n",
    "\n",
    "        toml\n",
    "        json\n",
    "        pickle\n",
    "        txt\n",
    "        ...\n",
    "        \"\"\"\n",
    "        if d is None:\n",
    "            d = self.load(self.x)\n",
    "        # make sure: dict\n",
    "        if isinstance(x, str):\n",
    "            writer = self.get_writer(x)\n",
    "            if writer is None:\n",
    "                log.error('unknown x, {}'.format(x))\n",
    "            else:\n",
    "                writer(d, x)\n",
    "        else:\n",
    "            log.warning('dump(x=) expect str, got {}'.format(\n",
    "                type(x).__name__))\n",
    "\n",
    "\n",
    "    def guess_format(self, x):\n",
    "        \"\"\"Guess the file format, by file extension\n",
    "    \n",
    "        file format:\n",
    "        - toml\n",
    "        - yaml\n",
    "        - json\n",
    "        - pickle\n",
    "\n",
    "        data format:\n",
    "        - dict\n",
    "        \"\"\"\n",
    "        formats = {\n",
    "            'json': 'json',\n",
    "            'yaml': 'yaml',\n",
    "            'yml': \"yaml\",\n",
    "            'toml': 'toml',\n",
    "            'pickle': 'pickle',\n",
    "            'txt': 'log',\n",
    "        }\n",
    "\n",
    "        if isinstance(x, str):\n",
    "            x_ext = os.path.splitext(x)[1]\n",
    "            x_ext = x_ext.lstrip('.').lower()\n",
    "            x_format = formats.get(x_ext, None)\n",
    "        elif isinstance(x, dict):\n",
    "            x_format = 'dict'\n",
    "        else:\n",
    "            x_format = None\n",
    "\n",
    "        return x_format\n",
    "\n",
    "\n",
    "    def get_reader(self, x):\n",
    "        \"\"\"Get the reader for file x, based on the file extension\n",
    "    \n",
    "        could be: json/yaml/toml/pickle\n",
    "        \"\"\"\n",
    "        x_format = self.guess_format(x)\n",
    "        readers = {\n",
    "            'json': self.from_json,\n",
    "            'yaml': self.from_yaml,\n",
    "            'toml': self.from_toml,\n",
    "            'pickle': self.from_pickle\n",
    "        }\n",
    "        return readers.get(x_format, None)\n",
    "\n",
    "\n",
    "    def get_writer(self, x):\n",
    "        \"\"\"Get the reader for file x, based on the file extension\n",
    "\n",
    "        could be: json/yaml/toml/pickle\n",
    "        \"\"\"\n",
    "        x_format = self.guess_format(x)\n",
    "        writers = {\n",
    "            'json': self.to_json,\n",
    "            'yaml': self.to_yaml,\n",
    "            'toml': self.to_toml,\n",
    "            'pickle': self.to_pickle,\n",
    "            'log': self.to_log,\n",
    "        }\n",
    "        return writers.get(x_format, None)\n",
    "\n",
    "\n",
    "    def from_json(self, x):\n",
    "        \"\"\"Loding data from JSON file\n",
    "        x should be file\n",
    "        \"\"\"\n",
    "        d = None\n",
    "        if file_exists(x):\n",
    "            try:\n",
    "                with open(x, 'r') as r:\n",
    "                    if os.path.getsize(x) > 0:\n",
    "                        d = json.load(r)\n",
    "                        d = collections.OrderedDict(sorted(d.items()))\n",
    "            except Exception as exc:\n",
    "                log.error('from_json() failed, {}'.format(exc))\n",
    "            finally:\n",
    "                return d\n",
    "        else:\n",
    "            log.error('from_json() failed, file not exists: {}'.format(x))\n",
    "\n",
    "\n",
    "    def from_yaml(self, x):\n",
    "        \"\"\"Loding data from YAML file\n",
    "        x should be file\n",
    "        \"\"\"\n",
    "        d = None\n",
    "        if file_exists(x):\n",
    "            try:\n",
    "                with open(x, 'r') as r:\n",
    "                    if os.path.getsize(x) > 0:\n",
    "                        d = yaml.load(r, Loader=yaml.FullLoader)\n",
    "                        d = collections.OrderedDict(sorted(d.items()))\n",
    "            except Exception as exc:\n",
    "                log.error('from_yaml() failed, {}'.format(exc))\n",
    "            finally:\n",
    "                return d\n",
    "        else:\n",
    "            log.error('from_yaml() failed, file not exists: {}'.format(x))\n",
    "        # with open(x, 'r') as r:\n",
    "        #     try:\n",
    "        #         d = yaml.safe_load(r)\n",
    "        #         return collections.OrderedDict(sorted(d.items()))\n",
    "        #     except yaml.YAMLError as exc:\n",
    "        #         log.warning(exc)\n",
    "\n",
    "\n",
    "    def from_toml(self, x):\n",
    "        \"\"\"Loding data from TOML file\n",
    "        x should be file\n",
    "        \"\"\"\n",
    "        d = None\n",
    "        if file_exists(x):\n",
    "            try:\n",
    "                with open(x, 'r') as r:\n",
    "                    if os.path.getsize(x) > 0:\n",
    "                        d = toml.load(x)\n",
    "                        d = collections.OrderedDict(sorted(d.items()))\n",
    "            except Exception as exc:\n",
    "                log.error('from_toml() failed, {}'.format(exc))\n",
    "            finally:\n",
    "                return d\n",
    "        else:\n",
    "            log.error('from_toml() failed, file not exists: {}'.format(x))\n",
    "\n",
    "\n",
    "    def from_pickle(self, x):\n",
    "        \"\"\"Loding data from pickle file\n",
    "        x should be file\n",
    "        \"\"\"\n",
    "        d = None\n",
    "        if file_exists(x):\n",
    "            try:\n",
    "                with open(x, 'rb') as r:\n",
    "                    if os.path.getsize(x) > 0:\n",
    "                        d = pickle.load(r)\n",
    "                        d = collections.OrderedDict(sorted(d.items()))\n",
    "            except Exception as exc:\n",
    "                log.error('from_pickle() failed, {}'.format(exc))\n",
    "            finally:\n",
    "                return d\n",
    "        else:\n",
    "            log.error('from_pickle() failed, file not exists: {}'.format(x))\n",
    "\n",
    "\n",
    "    def to_json(self, d, x):\n",
    "        \"\"\"Writing data to JSON file\n",
    "        d dict, data to file\n",
    "        x None or str, path to JSON file, or return string\n",
    "        \"\"\"\n",
    "        x = file_abspath(x)\n",
    "        if not isinstance(d, dict):\n",
    "            log.error('to_json(d=) failed, dict expect, got {}'.format(\n",
    "                type(d).__name__))\n",
    "        elif not isinstance(x, str):\n",
    "            log.error('to_json(d=) failed, str expect, got {}'.format(\n",
    "                type(x).__name__))\n",
    "        elif not file_exists(os.path.dirname(x), isfile=False):\n",
    "            log.error('to_json(x=) failed, file not exists: {}'.format(x))\n",
    "        else:\n",
    "            try:\n",
    "                with open(x, 'wt') as w:\n",
    "                    json.dump(d, w, indent=4, sort_keys=True)\n",
    "                # return x\n",
    "            except Exception as exc:\n",
    "                log.error('to_json() failed, {}'.format(exc))\n",
    "\n",
    "\n",
    "    def to_yaml(self, d, x):\n",
    "        \"\"\"Writing data to YAML file\n",
    "        d dict, data to file\n",
    "        x str, path to YAML file\n",
    "\n",
    "        yaml.dump(), does not support OrderedDict\n",
    "        Solution: OrderedDict -> json -> dict\n",
    "        \"\"\"\n",
    "        # x_yaml = x\n",
    "        # x = os.path.splitext(x_yaml)[0] + '.toml'\n",
    "        # log.warning('OrderedDict is not supported in YAML, save as TOML instead: {}'.format(x))\n",
    "        # check\n",
    "        x = file_abspath(x)\n",
    "        if not isinstance(d, dict):\n",
    "            log.error('to_yaml(d=) failed, dict expect, got {}'.format(\n",
    "                type(d).__name__))\n",
    "        elif not isinstance(x, str):\n",
    "            log.error('to_yaml(d=) failed, str expect, got {}'.format(\n",
    "                type(x).__name__))\n",
    "        elif not file_exists(os.path.dirname(x), isfile=False):\n",
    "            log.error('to_yaml(x=) failed, file not exists: {}'.format(x))\n",
    "        else:\n",
    "            try:\n",
    "                with open(x, 'wt') as w:\n",
    "                    # toml.dump(d, w)\n",
    "                    yaml.dump(dict(d), w)\n",
    "                # return x\n",
    "            except Exception as exc:\n",
    "                log.error('to_yaml() failed, {}'.format(exc))\n",
    "\n",
    "\n",
    "    def to_toml(self, d, x):\n",
    "        \"\"\"Writing data to TOML file\n",
    "        d dict, data to file\n",
    "        x str, path to TOML file\n",
    "        \"\"\"        \n",
    "        x = file_abspath(x)\n",
    "        if not isinstance(d, dict):\n",
    "            log.error('to_toml(d=) failed, dict expect, got {}'.format(\n",
    "                type(d).__name__))\n",
    "        elif not isinstance(x, str):\n",
    "            log.error('to_toml(d=) failed, str expect, got {}'.format(\n",
    "                type(x).__name__))\n",
    "        elif not file_exists(os.path.dirname(x), isfile=False):\n",
    "            log.error('to_toml(d=) failed, file not exists: {}'.format(x))\n",
    "        else:\n",
    "            try:\n",
    "                with open(x, 'wt') as w:\n",
    "                    toml.dump(d, w)\n",
    "                # return x\n",
    "            except Exception as exc:\n",
    "                log.error('to_toml() failed, {}'.format(exc))\n",
    "\n",
    "\n",
    "    def to_pickle(self, d, x):\n",
    "        \"\"\"Writing data to pickle file\n",
    "        d dict, data to file\n",
    "        x str, path to pickle file\n",
    "        \"\"\"        \n",
    "        x = file_abspath(x)\n",
    "        if not isinstance(d, dict):\n",
    "            log.error('to_pickle(d=) failed, dict expect, got {}'.format(\n",
    "                type(d).__name__))\n",
    "        elif not isinstance(x, str):\n",
    "            log.error('to_pickle(x=) failed, str expect, got {}'.format(\n",
    "                type(x).__name__))\n",
    "        elif not file_exists(os.path.dirname(x), isfile=False):\n",
    "            log.error('to_pickle(x=) failed, file not exists: {}'.format(x))\n",
    "        else:\n",
    "            try:\n",
    "                with open(x, 'wb') as w:\n",
    "                    pickle.dump(d, w, protocol=pickle.HIGHEST_PROTOCOL)\n",
    "                # return x\n",
    "            except Exception as exc:\n",
    "                log.error('to_pickle() failed, {}'.format(exc))\n",
    "\n",
    "\n",
    "    def to_log(self, d, x, stdout=False):\n",
    "        \"\"\"Writing data to log file: key: value format\n",
    "        d dict, data to file\n",
    "        x str, path to pickle file\n",
    "        \"\"\"\n",
    "        x = file_abspath(x)\n",
    "        if not isinstance(d, dict):\n",
    "            log.error('to_log(d=) failed, dict expect, got {}'.format(\n",
    "                type(d).__name__))\n",
    "        elif not isinstance(x, str):\n",
    "            log.error('to_log(x=) failed, str expect, got {}'.format(\n",
    "                type(x).__name__))\n",
    "        elif not file_exists(os.path.dirname(x), isfile=False):\n",
    "            log.error('to_log(x=) failed, file not exists: {}'.format(x))\n",
    "        else:\n",
    "            try:\n",
    "                # organize msg\n",
    "                msg = []\n",
    "                for k, v in d.items():\n",
    "                    if isinstance(v, str) or isinstance(v, numbers.Number) or isinstance(v, bool):\n",
    "                        v = str(v)\n",
    "                    elif isinstance(v, list):\n",
    "                        v = ', '.join(map(str, v))\n",
    "                    else:\n",
    "                        v = '...' # skip\n",
    "                    msg.append('{:30s} | {:<40s}'.format(k, v))\n",
    "                # save\n",
    "                with open(x, 'wt') as w:\n",
    "                    w.write('\\n'.join(msg) + '\\n')\n",
    "                if stdout:\n",
    "                    print('\\n'.join(msg))\n",
    "                # return x\n",
    "            except Exception as exc:\n",
    "                log.error('to_log() failed, {}'.format(exc))\n",
    "\n",
    "\n",
    "    def _tmp(self, suffix='.txt'):\n",
    "        \"\"\"\n",
    "        Create a tmp file to save json object\n",
    "        \"\"\"\n",
    "        tmp = tempfile.NamedTemporaryFile(prefix='tmp', suffix=suffix,\n",
    "            delete=False)\n",
    "        return tmp.name\n",
    "    \n",
    "    \n",
    "    \n",
    "# df = Config().load('./aaaa.json')\n",
    "# Config().dump(df, './aaaa.txt')\n",
    "# Config().dump(df, './aaaa.json')\n",
    "#df = Config().load('./aaaa.json')\n",
    "#Config().dump(df, 'aaaa.pickle')\n",
    "df = {'aaa': 1, 'BBB': 2}\n",
    "Config().dump(df, 'aaaa.yaml')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "objective-forth",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
